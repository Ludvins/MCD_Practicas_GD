{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Luis Antonio Ortega Andrés   \n",
    "Antonio Coín Castro*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:31:07.119494Z",
     "start_time": "2020-12-17T00:31:05.692185Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestión de Datos - Práctica 2\n",
    "\n",
    "Disponemos de dos conjuntos de datos sobre valoraciones de películas que se actualizan diariamente, sobre los que queremos realizar de forma eficiente una consulta. La consulta que se pretende implementar a partir de los datos es una que retorne la lista de géneros, ordenados por el promedio de puntuación que han obtenido\n",
    "en la última semana.\n",
    "\n",
    "Se deberá realizar un trabajo de procesado de datos que al menos debe contener las\n",
    "fases de carga, tratamiento de valores perdidos, normalización de los datos cuando sea\n",
    "necesario y limpieza de outliers. Finalmente, los datos se deben almacenar de forma\n",
    "estructurada que facilite la consulta propuesta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de los datos disponibles\n",
    "\n",
    "### Carga de datos\n",
    "\n",
    "El primer paso a seguir es cargar los datos disponibles en los ficheros `movies.csv` y `ratings.csv` en sendos dataframes para su exploración y procesamiento. En lo sucesivo nos referiremos al dataframe de películas como `dfm` y al de valoraciones como `dfr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:31:44.560478Z",
     "start_time": "2020-12-17T00:31:07.127417Z"
    }
   },
   "outputs": [],
   "source": [
    "dfm = pd.read_csv(\"movies.csv\")\n",
    "dfr = pd.read_csv(\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echamos un vistazo a la configuración de los datos:\n",
    "\n",
    "- Para las películas, vemos que existen tres campos: el identificador de película (`movieId`), el título de la misma (`title`) y una lista de géneros asociada a la misma, separada por \"|\" (`genres`). Hay un total de 62423 entradas.\n",
    "\n",
    "- En cuanto a las valoraciones, existen cuatro campos relevantes: el identificador del usuario que realizó la valoración (`userId`), el identificador de película para cruzar esta tabla con la anterior (`movieId`), la valoración realizada sobre 5 estrellas e incrementos de media estrella (`rating`), y la fecha en la que se hizo, medida en segundos desde el 1 de enero de 1970 UTC (`timestamp`). Tenemos un total de 25000095 entradas, y destacamos que todas las columnas tienen valores numéricos (comprobado con la función `.info()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:31:44.651708Z",
     "start_time": "2020-12-17T00:31:44.568063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfm] Tamaño: (62423, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[dfm] Tamaño:\", dfm.shape)\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:31:44.715591Z",
     "start_time": "2020-12-17T00:31:44.661516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfr] Tamaño: (25000095, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[dfr] Tamaño:\", dfr.shape)\n",
    "dfr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos duplicados\n",
    "\n",
    "Antes de nada, debemos asegurarnos en la medida de lo posible que el conjunto de datos es consistente, y principalmente de que no hay entradas repetidas que sean contradictorias. Vamos a asumir que el sistema de recogida de datos no permite errores del tipo \"un mismo usuario valora la misma película en dos ocasiones distintas\", y en general vamos a ignorar errores de esta naturaleza que no afecten a nuestra consulta final. \n",
    "\n",
    "Lo único que hacemos a este respecto es eliminar las filas completamente repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:32:25.818403Z",
     "start_time": "2020-12-17T00:31:44.723400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfm] Filas duplicadas: 0\n",
      "[dfr] Filas duplicadas: 8\n"
     ]
    }
   ],
   "source": [
    "rows_dfm = len(dfm)\n",
    "rows_dfr = len(dfr)\n",
    "dfm = dfm.drop_duplicates()\n",
    "dfr = dfr.drop_duplicates()\n",
    "print(\"[dfm] Filas duplicadas:\", rows_dfm - len(dfm))\n",
    "print(\"[dfr] Filas duplicadas:\", rows_dfr - len(dfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores perdidos\n",
    "\n",
    "Para analizar los valores perdidos iremos campo a campo en cada dataframe.\n",
    "\n",
    "**dfm**\n",
    "\n",
    "Para las películas, si el campo `movieId` no está presente o no es numérico, descartamos toda la fila, ya que si no está presente no tenemos forma de saber cuál es el identificador de la película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:32:25.999326Z",
     "start_time": "2020-12-17T00:32:25.822652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfm] Filas con movieId inválido: 0\n"
     ]
    }
   ],
   "source": [
    "rows_dfm = len(dfm)\n",
    "dfm = dfm[dfm.movieId.apply(lambda x: np.isreal(x))]\n",
    "dfm = dfm.dropna(subset=['movieId'])\n",
    "print(\"[dfm] Filas con movieId inválido:\", rows_dfm - len(dfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nos importa el valor del campo `title` siempre que el `movieId` sea válido. En cuanto a `genres`, sabemos que deben estar separados por \"|\" cuando haya más de uno, y supondremos que solo pueden contener letras mayúsculas y minúsculas, guiones y espacios en blanco. En primer lugar miramos cuáles son los valores únicos en nuestro dataset para este campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:32:26.243804Z",
     "start_time": "2020-12-17T00:32:26.004455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(no genres listed)', 'Action', 'Adventure', 'Animation',\n",
       "       'Children', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
       "       'Espionage Action', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX',\n",
       "       'Musical', 'Mystery', 'Psychological Thriller', 'Romance',\n",
       "       'Sci-Fi', 'Thriller', 'War', 'Western'], dtype='<U22')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [g.split(\"|\") for g in list(dfm['genres'])]\n",
    "np.unique(list(chain.from_iterable(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la forma de indicar que no hay información disponible sobre el género es la cadena '(no genres listed)', por lo que si en alguna fila está presente, descartamos la fila completa (ya que no es útil para nuestra consulta final). No hay más valores discordantes, pero por si acaso, hacemos lo mismo buscando valores NaN en ese campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:32:26.288231Z",
     "start_time": "2020-12-17T00:32:26.251007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfm] Filas con genres no presente: 5062\n"
     ]
    }
   ],
   "source": [
    "rows_dfm = len(dfm)\n",
    "dfm = dfm[dfm['genres'] != '(no genres listed)']\n",
    "dfm = dfm.dropna(subset=['genres'])\n",
    "print(\"[dfm] Filas con genres no presente:\", rows_dfm - len(dfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dfr**\n",
    "\n",
    "El campo `userId` no nos importa que sea inválido para nuestra consulta final. Para el campo `movieId` hacemos lo mismo que antes, por el mismo motivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:33:35.081675Z",
     "start_time": "2020-12-17T00:32:26.292817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfr] Filas con movieId inválido: 0\n"
     ]
    }
   ],
   "source": [
    "rows_dfr = len(dfr)\n",
    "dfr = dfr.dropna(subset=['movieId'])\n",
    "dfr = dfr[dfr.movieId.apply(lambda x: np.isreal(x))]\n",
    "print(\"[dfr] Filas con movieId inválido:\", rows_dfr - len(dfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a `rating`, como es la variable clave sobre la que vamos a hacer la consulta, debemos asegurarnos de que está presente y que tiene un valor válido (es decir, un número en $[0,5]$ que sea múltiplo de $0.5$). En otro caso descartamos la fila completa, ya que no tendría sentido imputar ningún valor, pues estaríamos modificando significativamente el promedio sin tener una razón estadística de peso que lo sugiriese.\n",
    "\n",
    "Esto es así ya que la única información relevante de la tabla `dfr` es justamente la valoración, y sin ella toda la entrada se vuelve irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:35:14.082656Z",
     "start_time": "2020-12-17T00:33:35.086243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfr] Filas con rating inválido: 505332\n"
     ]
    }
   ],
   "source": [
    "rows_dfr = len(dfr)\n",
    "dfr = dfr.dropna(subset=['rating'])\n",
    "dfr = dfr[dfr.rating.apply(lambda x: np.isreal(x) and x >= 0 \n",
    "                           and x <= 5 and int(2*x) == 2*x)]\n",
    "print(\"[dfr] Filas con rating inválido:\", rows_dfr - len(dfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, para el campo `timestamp` seguimos la misma filosofía: comprobamos que esté presente y que sea válido, pues de otro modo no tendremos forma de saber cuándo se produjo la valoración, que es algo que nos interesa en nuestra consulta final. En este caso, un valor válido será un número entre $0$ y el *timestamp* actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:37:26.435085Z",
     "start_time": "2020-12-17T00:35:14.088706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfr] Filas con timestamp inválido: 0\n"
     ]
    }
   ],
   "source": [
    "rows_dfr = len(dfr)\n",
    "dfr = dfr.dropna(subset=['timestamp'])\n",
    "dfr = dfr[dfr.timestamp.apply(lambda x: np.isreal(x) and x >= 0 \n",
    "                           and x <= time.time())]\n",
    "print(\"[dfr] Filas con timestamp inválido:\", rows_dfr - len(dfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de datos\n",
    "\n",
    "En este caso no es necesario normalizar los datos. El único campo numérico que podría tener interés es el de `rating`, pero tras la limpieza realizada nos hemos asegurado que todos los valores se encuentran en la escala predefinida en $[0,5]$. Como en nuestra consulta final no vamos a comparar variables distintas, no es necesario normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de *outliers*\n",
    "\n",
    "El único valor para el que tendría sentido buscar *outliers* es el de `rating`, y quizás el de `timestamp`.  Sin embargo, valores fuera del rango permitido para estas dos variables no serían *outliers*, sino directamente valores inválidos (que ya hemos limpiado previamente). Además, si hubiera valores dentro del rango permitido pero alejados de la mayoría, seguirían siendo igual de válidos y no podrían considerarse *outliers*, al menos en lo que respecta a nuestra consulta objetivo (no tendría sentido tratar distinto una puntuación de 0 estrellas, incluso aunque la mayoría de puntuaciones fueran de 5 estrellas, siempre y cuando nos hayamos asegurado de que son datos válidos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas\n",
    "\n",
    "Mostramos un pequeño resumen estadístico de los valores modificados de una forma u otra en el análisis y limpieza del dataset.\n",
    "\n",
    "**dfm**\n",
    "\n",
    "| Duplicados | Valores perdidos o inválidos | Outliers | \n",
    "|:----------:|:----------------------------:|:--------:|\n",
    "| 0 | 5062 | 0 |\n",
    "\n",
    "| Transformación (en orden) | Nº registros antes | Nº registros después |\n",
    "|:--------------:|:------------------:|:------------------------:|\n",
    "| Duplicados | 62423 | 62423 |\n",
    "| Valores perdidos o inválidos | 62423 | 57361 |\n",
    "| Outliers | 57361 | 57361 |\n",
    "\n",
    "**dfr**\n",
    "\n",
    "| Duplicados | Valores perdidos o inválidos | Outliers | \n",
    "|:----------:|:----------------------------:|:--------:|\n",
    "| 8 | 505332 | 0 |\n",
    "\n",
    "| Transformación (en orden) | Nº registros antes | Nº registros después |\n",
    "|:--------------:|:------------------:|:------------------------:|\n",
    "| Duplicados | 25000095 | 25000087 |\n",
    "| Valores perdidos o inválidos | 25000087 | 24494755 |\n",
    "| Outliers | 24494755 | 24494755 |\n",
    "\n",
    "Concluimos que todos los valores eliminados del conjunto sea por la razón que sea constituyen un pequeño porcentaje del total en cada caso, por lo que en principio no tenemos por qué preocuparnos por haber perdido muchos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos futuros\n",
    "\n",
    "Suponemos que estos datos se actualizan todos los días a las 3 AM hora local. Nuestro objetivo es realizar este mismo preprocesamiento y limpieza con los nuevos datos, y después convertirlos a un formato adecuado para poder realizar la consulta final. No haremos ninguna suposición sobre actualizaciones incrementales de los datos, es decir, supondremos que es posible que de un día al siguiente se modifiquen datos antiguos, en lugar de solo añadir datos nuevos. Esto significa también que no reutilizaremos información de un día para el siguiente.\n",
    "\n",
    "El único campo que merece un poco más de atención es la lista de géneros en la tabla de películas. **Supondremos que los datos futuros seguirán la misma expresión regular que los actuales**, es decir, los géneros se separarán por \"|\" y estarán formados únicamente por letras mayúsculas y minúsculas, guiones y espacios. Cualquier otra cadena se considerará un valor inválido. En el script realizado se implementa la comprobación de esta expresión regular.\n",
    "\n",
    "El tratamiento automatizado de los datos se implementa en el script `limpieza.py`, y la conversión al formato deseado en `conv.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración con airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "bibliography.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
